{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70046e1",
   "metadata": {},
   "source": [
    "## âš™ï¸ í™˜ê²½ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1995df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸  torth ì„¤ì • ì™„ë£Œ\n",
      "âš™ï¸  classì •ì˜ ì™„ë£Œ\n",
      "âš™ï¸  í™˜ê²½ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "print('âš™ï¸  torth ì„¤ì • ì™„ë£Œ')\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import matplotlib.pyplot as plt\n",
    "from public_function import MPerClassSampler\n",
    "print('âš™ï¸  í™˜ê²½ì„¤ì • ì™„ë£Œ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be6ddc0",
   "metadata": {},
   "source": [
    "## ğŸ“ŠëŒ€ì¡° í•™ìŠµìš© ë°ì´í„° ë¡œë”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c42a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸  ë°ì´íƒ€ì…‹ ë¡œë“œ ë° ë¡œë” ì •ì˜\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # ì´ë¯¸ì§€ í¬ê¸° ê³ ì •\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='my_dataset', transform=transform)\n",
    "sampler = MPerClassSampler(train_dataset.targets, m=4, length_before_new_iter=len(train_dataset))\n",
    "batch_size = 44\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=False, sampler=sampler\n",
    ")\n",
    "print('âš™ï¸  ë°ì´íƒ€ì…‹ ë¡œë“œ ë° ë¡œë” ì •ì˜')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262aea7",
   "metadata": {},
   "source": [
    "## âœ¨ëª¨ë¸ ë¡œë“œ ë° í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be7e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸  ê¸°ë³¸ ëª¨ë¸ í˜•íƒœ ë¡œë”© ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ì ì¸ ëª¨ë¸\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "#ëª¨ë¸ GPUë¡œ ê°€ëŠ¥í•˜ë©´ ì˜®ê¸°ê¸°\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet18()\n",
    "model = model.to(device)\n",
    "print('âš™ï¸  ê¸°ë³¸ ëª¨ë¸ í˜•íƒœ ë¡œë”© ì™„ë£Œ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4253f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸  ë¹ ë¥¸ ì†ì‹¤ê°’ ê³„ì‚°í•¨ìˆ˜\n"
     ]
    }
   ],
   "source": [
    "# ë¹ ë¥¸ ì†ì‹¤ê°’ ê³„ì‚° í•¨ìˆ˜ ì •ì˜\n",
    "def contrastive_loss_fast(features, labels, margin=0.3):\n",
    "    features = features / (torch.norm(features, p=2, dim=1, keepdim=True) + 1e-12).expand_as(features)\n",
    "    distance_matrix = torch.cdist(features, features, p=2)\n",
    "    labels_expanded = labels.unsqueeze(0).expand(len(labels), len(labels))\n",
    "    label_matrix = (labels_expanded == labels_expanded.t()).byte()\n",
    "    label_matrix.fill_diagonal_(0)  # Exclude self-comparison\n",
    "    same_loss = label_matrix * distance_matrix.pow(2)\n",
    "    different_loss = (1 - label_matrix) * torch.pow(torch.clamp(margin - distance_matrix, min=0.0), 2)\n",
    "    loss = same_loss + different_loss\n",
    "    return loss.mean()\n",
    "print('âš™ï¸  ë¹ ë¥¸ ì†ì‹¤ê°’ ê³„ì‚°í•¨ìˆ˜')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a61a982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [11:52<00:46, 15.39s/it, í˜„ì¬ Epoch=0, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0353]c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:39<00:00, 15.18s/it, í˜„ì¬ Epoch=0, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0359]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:34<00:00, 15.08s/it, í˜„ì¬ Epoch=1, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0341]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:35<00:00, 15.11s/it, í˜„ì¬ Epoch=2, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0288]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:36<00:00, 15.13s/it, í˜„ì¬ Epoch=3, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0293]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:32<00:00, 15.06s/it, í˜„ì¬ Epoch=4, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0289]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:38<00:00, 15.17s/it, í˜„ì¬ Epoch=5, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0301]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:36<00:00, 15.14s/it, í˜„ì¬ Epoch=6, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0265]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:44<00:00, 15.30s/it, í˜„ì¬ Epoch=7, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0287]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:38<00:00, 15.16s/it, í˜„ì¬ Epoch=8, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0220]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:43<00:00, 15.27s/it, í˜„ì¬ Epoch=9, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0222]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:43<00:00, 15.28s/it, í˜„ì¬ Epoch=10, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0225]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:37<00:00, 15.15s/it, í˜„ì¬ Epoch=11, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0232]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:33<00:00, 15.07s/it, í˜„ì¬ Epoch=12, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0211]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:33<00:00, 15.08s/it, í˜„ì¬ Epoch=13, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0228]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:40<00:00, 15.21s/it, í˜„ì¬ Epoch=14, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0207]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:38<00:00, 15.18s/it, í˜„ì¬ Epoch=15, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0186]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:46<00:00, 15.34s/it, í˜„ì¬ Epoch=16, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0187]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:42<00:00, 15.24s/it, í˜„ì¬ Epoch=17, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0191]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:27<00:00, 14.95s/it, í˜„ì¬ Epoch=18, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0170]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:31<00:00, 15.04s/it, í˜„ì¬ Epoch=19, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0168]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:33<00:00, 15.06s/it, í˜„ì¬ Epoch=20, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0165]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:23<00:00, 14.86s/it, í˜„ì¬ Epoch=21, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0172]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:30<00:00, 15.02s/it, í˜„ì¬ Epoch=22, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0165]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:30<00:00, 15.02s/it, í˜„ì¬ Epoch=23, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0177]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:32<00:00, 15.05s/it, í˜„ì¬ Epoch=24, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0164]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:33<00:00, 15.07s/it, í˜„ì¬ Epoch=25, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0155]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:30<00:00, 15.00s/it, í˜„ì¬ Epoch=26, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0149]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:30<00:00, 15.02s/it, í˜„ì¬ Epoch=27, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0160]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:25<00:00, 14.90s/it, í˜„ì¬ Epoch=28, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0144]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:30<00:00, 15.00s/it, í˜„ì¬ Epoch=29, í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’=0.0155]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸  í•™ìŠµì´ ì™„ë£Œë¨\n",
      "ğŸ’¾ ëª¨ë¸ì´ 'trained_model.pth' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 30\n",
    "margin = 0.75\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.0001)\n",
    "for i in range(epoch):\n",
    "    progress_bar = tqdm(train_dataloader)  # ì§„í–‰ë°”ë¥¼ ì¶œë ¥í•˜ì—¬, í•™ìŠµ ê³¼ì •ì„ ëˆˆìœ¼ë¡œ ë³´ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤!\n",
    "\n",
    "    for data in progress_bar:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        features = model(images)\n",
    "        loss = contrastive_loss_fast(features, labels, margin)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.set_postfix({\"í˜„ì¬ Epoch\": i, \"í˜„ì¬ ëŒ€ì¡° ì†ì‹¤ ê°’\": f\"{loss.item():.4f}\"})\n",
    "print(f'âš™ï¸  í•™ìŠµì´ ì™„ë£Œë¨')\n",
    "\n",
    "torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "print(\"ğŸ’¾ ëª¨ë¸ì´ 'trained_model.pth' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
